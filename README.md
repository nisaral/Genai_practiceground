# Genai_practiceground
## transformer architecture
Transformer models use self-attention mechanisms to weigh the
importance of different words in a sentence, consisting of an encoder to
process input text and a decoder to generate output text, with parallel
processing enabling efficient training.


![image](https://github.com/user-attachments/assets/57f20652-4d16-41ba-8886-086d3692513b)
